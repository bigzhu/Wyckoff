import os
import sys
import argparse
import requests
import pandas as pd
import glob
import time

# è®© Python èƒ½å¤Ÿæ‰¾åˆ° .env æ–‡ä»¶ (ä½äºé¡¹ç›®æ ¹ç›®å½•)
# å‡è®¾è„šæœ¬åœ¨ docs/æŒ‡æ ‡å·¥å…·ç®±/AI/ ä¸‹ï¼Œ.env åœ¨ ../../../ ä¸‹
# ç®€å•èµ·è§ï¼Œä»å½“å‰æ‰§è¡Œç›®å½•æˆ–çˆ¶ç›®å½•æŸ¥æ‰¾
def load_env_key():
    # å°è¯•è¯»å– .env æ–‡ä»¶çš„ç®€å•å®ç°ï¼Œä¸ä¾èµ– python-dotenv
    env_paths = [".env", "../../../.env", "docs/æŒ‡æ ‡å·¥å…·ç®±/AI/../../../../.env"]
    for path in env_paths:
        if os.path.exists(path):
            with open(path, "r") as f:
                for line in f:
                    if line.startswith("GOOGLE_API_KEY="):
                        return line.strip().split("=", 1)[1]
    return None

API_KEY = load_env_key() or os.environ.get("GOOGLE_API_KEY")

if not API_KEY:
    print("âŒ æœªæ‰¾åˆ° GOOGLE_API_KEYï¼Œè¯·æ£€æŸ¥ .env æ–‡ä»¶ã€‚")
    sys.exit(1)

# Gemini API Endpoint
# Verified stable model for Free Tier: gemini-flash-latest
MODEL_NAME = "gemini-flash-latest"
API_URL = f"https://generativelanguage.googleapis.com/v1beta/models/{MODEL_NAME}:generateContent?key={API_KEY}"

def get_ai_analysis(system_prompt, data_context):
    headers = {"Content-Type": "application/json"}
    
    # æ„é€  Prompt
    # å°†ç³»ç»Ÿæç¤ºè¯å’Œæ•°æ®åˆå¹¶å‘é€
    full_prompt = f"""
{system_prompt}

---

### å½“å‰å¸‚åœºæ•°æ® (CSV ç‰‡æ®µ)
(ä»…æä¾›æœ€è¿‘çš„æ•°æ®ä»¥ä¾¿åˆ†æï¼Œè¯·åŸºäºæ­¤æ•°æ®è¿›è¡Œæ¨æ¼”)

{data_context}
    """
    
    payload = {
        "contents": [{
            "parts": [{"text": full_prompt}]
        }],
        "generationConfig": {
            "temperature": 0.3, # åˆ†æç±»ä»»åŠ¡å»ºè®®ä½æ¸©åº¦
            "maxOutputTokens": 8192
        }
    }
    
    max_retries = 6
    retry_delay = 10
    
    for attempt in range(max_retries):
        try:
            response = requests.post(API_URL, json=payload, headers=headers, timeout=60)
            if response.status_code == 200:
                result = response.json()
                try:
                    text = result['candidates'][0]['content']['parts'][0]['text']
                    return text
                except (KeyError, IndexError):
                    print(f"âŒ è§£æå“åº”å¤±è´¥: {result}")
                    return None
            elif response.status_code == 429:
                print(f"âš ï¸ è§¦å‘é¢‘ç‡é™åˆ¶ (429)ï¼Œç­‰å¾… {retry_delay} ç§’åé‡è¯•... ({attempt + 1}/{max_retries})")
                time.sleep(retry_delay)
                retry_delay *= 2 # æŒ‡æ•°é€€é¿
                continue
            else:
                print(f"âŒ API è¯·æ±‚å¤±è´¥: {response.status_code} - {response.text}")
                return None
        except Exception as e:
            print(f"âŒ ç½‘ç»œè¯·æ±‚å¼‚å¸¸: {e}")
            return None
            
    print("âŒ é‡è¯•æ¬¡æ•°è€—å°½ï¼Œåˆ†æå¤±è´¥ã€‚")
    return None

def main():
    parser = argparse.ArgumentParser(description='ä½¿ç”¨ Gemini AI åˆ†æå¨ç§‘å¤«è¡Œæƒ…')
    parser.add_argument('csv_path', help='æ¸…æ´—åçš„ CSV æ•°æ®è·¯å¾„')
    args = parser.parse_args()
    
    csv_path = args.csv_path
    if not os.path.exists(csv_path):
        print(f"âŒ æ‰¾ä¸åˆ°æ–‡ä»¶: {csv_path}")
        return

    # 1. å‡†å¤‡ Prompt
    prompt_path = os.path.join(os.path.dirname(__file__), "æç¤ºè¯.md")
    if not os.path.exists(prompt_path):
         # å°è¯•ä» args[0] çš„ä½ç½®æ‰¾
         prompt_path = "docs/æŒ‡æ ‡å·¥å…·ç®±/AI/æç¤ºè¯.md"
         
    if os.path.exists(prompt_path):
        with open(prompt_path, "r", encoding="utf-8") as f:
            system_prompt = f.read()
    else:
        print("âš ï¸ æœªæ‰¾åˆ°æç¤ºè¯.mdï¼Œä½¿ç”¨é»˜è®¤ç®€æ˜“ Prompt")
        system_prompt = "è¯·å¯¹ä»¥ä¸‹å¨ç§‘å¤«è¡Œæƒ…æ•°æ®è¿›è¡Œä¸“ä¸šåˆ†æï¼Œè¯†åˆ« SC, AR, ST ç­‰å…³é”®äº‹ä»¶ã€‚"

    # 2. å‡†å¤‡æ•°æ®
    # [ä¼˜åŒ–] è¯»å–æœ€å 100 è¡Œ (å¤§å¹…å‡å°‘ Token æ¶ˆè€—ï¼Œé¿å… 429)
    # Gemini Free Tier limit is strict on RPM and TPM.
    df = pd.read_csv(csv_path)
    
    # è·å–åŸºæœ¬ä¿¡æ¯
    base_name = os.path.splitext(os.path.basename(csv_path))[0].replace("_Cleaned", "")
    
    # æˆªå–æ•°æ®
    recent_data = df.tail(100).to_csv(index=False)
    
    print(f"ğŸ§  æ­£è°ƒç”¨ Google Gemini ({MODEL_NAME}) è¿›è¡Œæ·±åº¦åˆ†æ...")
    print(f"ğŸ“„ åˆ†æå¯¹è±¡: {base_name} (æ•°æ®é•¿åº¦: {len(df)} -> æäº¤æœ€è¿‘ 100 è¡Œ)")

    analysis_text = get_ai_analysis(system_prompt, recent_data)
    
    if analysis_text:
        # 3. ä¿å­˜æŠ¥å‘Š
        # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦æ›¿æ¢æ‰ ai_analyze.py ç”Ÿæˆçš„æŠ¥å‘Šä¸­çš„å›¾ç‰‡è·¯å¾„å¼•ç”¨
        # æç¤ºè¯è¦æ±‚ç”Ÿæˆå›¾ç‰‡ï¼Œä½† AI åªç”Ÿæˆæ–‡æœ¬ã€‚
        # æˆ‘ä»¬å‡è®¾ output å›¾ç‰‡å·²ç»ç”± `wyckoff_plot.py` ç”Ÿæˆï¼Œåä¸º {base_name}_Wyckoff_Chart.png
        
        # å¼ºåˆ¶æ’å…¥å›¾ç‰‡é“¾æ¥ï¼ˆå¦‚æœ AI æ²¡ç”Ÿæˆæˆ–ç”Ÿæˆé”™äº†ï¼‰
        chart_filename = f"{base_name}_Wyckoff_Chart.png"
        img_link = f"![{base_name} Chart](./{chart_filename})"
        
        # ç®€å•çš„æ›¿æ¢/æ£€æŸ¥é€»è¾‘
        # å¦‚æœ AI è¿”å›çš„æ–‡æœ¬é‡Œæ²¡æœ‰å›¾ç‰‡é“¾æ¥ï¼Œæˆ‘ä»¬åœ¨å‰é¢åŠ ä¸€ä¸ª
        if chart_filename not in analysis_text:
            analysis_text = f"# å¨ç§‘å¤«æ·±åº¦åˆ†ææŠ¥å‘Š: {base_name}\n\n{img_link}\n\n{analysis_text}"
        
        # å†™å…¥æ–‡ä»¶
        # è¾“å‡ºç›®å½•åº”ä¸ wyckoff_plot.py ä¿æŒä¸€è‡´: docs/æŒ‡æ ‡å·¥å…·ç®±/AI/output/
        output_dir = "docs/æŒ‡æ ‡å·¥å…·ç®±/AI/output"
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)
            
        output_path = os.path.join(output_dir, f"{base_name}_Wyckoff_Analysis.md")
        
        with open(output_path, "w", encoding="utf-8") as f:
            f.write(analysis_text)
            
        print(f"âœ… AI åˆ†ææŠ¥å‘Šå·²ç”Ÿæˆ: {output_path}")
    else:
        print("âŒ åˆ†æå¤±è´¥ï¼Œæœªç”ŸæˆæŠ¥å‘Šã€‚")
        sys.exit(1)

if __name__ == "__main__":
    main()
